#!/usr/bin/env python3
"""
ì‹¤ì œ CMI ë°ì´í„°ì™€ ìŒì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ìœµí•© íŒŒì´í”„ë¼ì¸
"""

import numpy as np
import pandas as pd
import logging
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import json
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealDataFusionPipeline:
    """ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ìœµí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.cmi_data_path = "../../kmedi-guardian-seoul-2025/output/analysis/full_scale_clustered_data.parquet"
        self.voice_data_path = None  # ìŒì„± ë°ì´í„° ê²½ë¡œ í™•ì¸ í•„ìš”
        self.output_path = "./real_data_fusion_output"
        self.models_path = "./real_data_fusion_output/trained_models"
        self.results_path = "./real_data_fusion_output/training_results"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.output_path, exist_ok=True)
        os.makedirs(self.models_path, exist_ok=True)
        os.makedirs(self.results_path, exist_ok=True)
        
        logger.info("ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_cmi_data(self) -> Optional[pd.DataFrame]:
        """ì‹¤ì œ CMI ë°ì´í„° ë¡œë“œ"""
        try:
            logger.info("ğŸ“Š ì‹¤ì œ CMI ë°ì´í„° ë¡œë“œ ì‹œì‘")
            
            if not os.path.exists(self.cmi_data_path):
                logger.error(f"CMI ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.cmi_data_path}")
                return None
            
            # Parquet íŒŒì¼ ë¡œë“œ
            cmi_data = pd.read_parquet(self.cmi_data_path)
            
            logger.info(f"CMI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {cmi_data.shape}")
            logger.info(f"ì»¬ëŸ¼: {list(cmi_data.columns)}")
            
            # ë°ì´í„° ìƒ˜í”Œ í™•ì¸
            logger.info(f"ë°ì´í„° ìƒ˜í”Œ:\n{cmi_data.head()}")
            
            return cmi_data
            
        except Exception as e:
            logger.error(f"CMI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_cmi_data_structure(self, cmi_data: pd.DataFrame) -> Dict[str, Any]:
        """CMI ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        try:
            logger.info("ğŸ” CMI ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘")
            
            analysis = {
                'shape': cmi_data.shape,
                'columns': list(cmi_data.columns),
                'dtypes': cmi_data.dtypes.to_dict(),
                'missing_values': cmi_data.isnull().sum().to_dict(),
                'numeric_columns': [],
                'categorical_columns': [],
                'cluster_column': None,
                'sample_data': {}
            }
            
            # í´ëŸ¬ìŠ¤í„° ì»¬ëŸ¼ ì°¾ê¸°
            for col in cmi_data.columns:
                if 'cluster' in col.lower() or 'label' in col.lower():
                    analysis['cluster_column'] = col
                    break
            
            # ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ì»¬ëŸ¼ ë¶„ë¥˜
            for col in cmi_data.columns:
                if cmi_data[col].dtype in ['int64', 'float64']:
                    analysis['numeric_columns'].append(col)
                else:
                    analysis['categorical_columns'].append(col)
            
            # ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3ê°œ í–‰)
            for col in analysis['numeric_columns'][:5]:  # ì²˜ìŒ 5ê°œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ
                analysis['sample_data'][col] = cmi_data[col].head(3).tolist()
            
            logger.info(f"CMI ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì™„ë£Œ:")
            logger.info(f"  - ì „ì²´ í¬ê¸°: {analysis['shape']}")
            logger.info(f"  - í´ëŸ¬ìŠ¤í„° ì»¬ëŸ¼: {analysis['cluster_column']}")
            logger.info(f"  - ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(analysis['numeric_columns'])}ê°œ")
            logger.info(f"  - ë²”ì£¼í˜• ì»¬ëŸ¼: {len(analysis['categorical_columns'])}ê°œ")
            
            return analysis
            
        except Exception as e:
            logger.error(f"CMI ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def prepare_cmi_features(self, cmi_data: pd.DataFrame, analysis: Dict[str, Any]) -> Optional[np.ndarray]:
        """CMI ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            logger.info("ğŸ”§ CMI íŠ¹ì§• ì¶”ì¶œ ì‹œì‘")
            
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ (í´ëŸ¬ìŠ¤í„° ì»¬ëŸ¼ ì œì™¸)
            feature_columns = [col for col in analysis['numeric_columns'] 
                             if col != analysis['cluster_column']]
            
            if not feature_columns:
                logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¹˜í˜• íŠ¹ì§•ì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # íŠ¹ì§• ë°ì´í„° ì¶”ì¶œ
            features = cmi_data[feature_columns].values
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬ (í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´)
            features = np.nan_to_num(features, nan=np.nanmean(features))
            
            logger.info(f"CMI íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {features.shape}")
            logger.info(f"ì‚¬ìš©ëœ íŠ¹ì§•: {feature_columns}")
            
            return features
            
        except Exception as e:
            logger.error(f"CMI íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def create_voice_features_simulation(self, num_samples: int) -> np.ndarray:
        """ìŒì„± íŠ¹ì§• ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ìŒì„± ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)"""
        try:
            logger.info("ğŸµ ìŒì„± íŠ¹ì§• ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
            
            # ì‹¤ì œ ìŒì„± ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ CMI ë°ì´í„°ì™€ ë™ì¼í•œ ìƒ˜í”Œ ìˆ˜ë¡œ ì‹œë®¬ë ˆì´ì…˜
            # ì´ëŠ” ì„ì‹œ í•´ê²°ì±…ì´ë©°, ì‹¤ì œ ìŒì„± ë°ì´í„°ê°€ í™•ë³´ë˜ë©´ êµì²´í•´ì•¼ í•¨
            
            np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
            
            # ìŒì„± íŠ¹ì§• (8ê°œ ì°¨ì›)
            voice_features = np.random.normal(0, 1, (num_samples, 8))
            
            # íŠ¹ì§•ë³„ ì˜ë¯¸ìˆëŠ” ë²”ìœ„ ì„¤ì •
            voice_features[:, 0] = 150 + np.random.normal(0, 20, num_samples)  # pitch_hz
            voice_features[:, 1] = np.abs(np.random.normal(1.0, 0.3, num_samples))  # jitter_percent
            voice_features[:, 2] = np.abs(np.random.normal(1.0, 0.2, num_samples))  # shimmer_db
            voice_features[:, 3] = 20 + np.random.normal(0, 5, num_samples)  # hnr_db
            voice_features[:, 4] = np.clip(np.random.normal(0.5, 0.2, num_samples), 0.1, 1.0)  # energy
            voice_features[:, 5] = 1.0 + np.random.normal(0, 0.2, num_samples)  # speaking_rate
            voice_features[:, 6] = np.clip(np.random.normal(0.8, 0.2, num_samples), 0.6, 1.0)  # emotion_intensity
            voice_features[:, 7] = np.clip(np.random.normal(0.7, 0.2, num_samples), 0.3, 1.0)  # voice_quality
            
            logger.info(f"ìŒì„± íŠ¹ì§• ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: {voice_features.shape}")
            logger.warning("âš ï¸ ì´ëŠ” ì„ì‹œ í•´ê²°ì±…ì…ë‹ˆë‹¤. ì‹¤ì œ ìŒì„± ë°ì´í„° í™•ë³´ ì‹œ êµì²´ í•„ìš”")
            
            return voice_features
            
        except Exception as e:
            logger.error(f"ìŒì„± íŠ¹ì§• ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return None
    
    def fuse_features(self, cmi_features: np.ndarray, voice_features: np.ndarray) -> Optional[np.ndarray]:
        """CMIì™€ ìŒì„± íŠ¹ì§• ìœµí•©"""
        try:
            logger.info("ğŸ¯ íŠ¹ì§• ìœµí•© ì‹œì‘")
            
            if cmi_features.shape[0] != voice_features.shape[0]:
                logger.error(f"ìƒ˜í”Œ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: CMI {cmi_features.shape[0]} vs ìŒì„± {voice_features.shape[0]}")
                return None
            
            # íŠ¹ì§• ìœµí•© (ìˆ˜í‰ ì—°ê²°)
            fused_features = np.hstack([cmi_features, voice_features])
            
            logger.info(f"íŠ¹ì§• ìœµí•© ì™„ë£Œ: {fused_features.shape}")
            logger.info(f"  - CMI íŠ¹ì§•: {cmi_features.shape[1]}ê°œ")
            logger.info(f"  - ìŒì„± íŠ¹ì§•: {voice_features.shape[1]}ê°œ")
            logger.info(f"  - ìœµí•© íŠ¹ì§•: {fused_features.shape[1]}ê°œ")
            
            return fused_features
            
        except Exception as e:
            logger.error(f"íŠ¹ì§• ìœµí•© ì‹¤íŒ¨: {e}")
            return None
    
    def create_labels(self, cmi_data: pd.DataFrame, analysis: Dict[str, Any]) -> Optional[np.ndarray]:
        """ë¼ë²¨ ìƒì„± (í´ëŸ¬ìŠ¤í„° ì •ë³´ ì‚¬ìš©)"""
        try:
            logger.info("ğŸ·ï¸ ë¼ë²¨ ìƒì„± ì‹œì‘")
            
            if not analysis['cluster_column']:
                logger.error("í´ëŸ¬ìŠ¤í„° ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ë¼ë²¨ë¡œ ì‚¬ìš©
            labels = cmi_data[analysis['cluster_column']].values
            
            # í´ëŸ¬ìŠ¤í„° ë¶„í¬ í™•ì¸
            unique_labels, counts = np.unique(labels, return_counts=True)
            logger.info(f"í´ëŸ¬ìŠ¤í„° ë¶„í¬:")
            for label, count in zip(unique_labels, counts):
                percentage = (count / len(labels)) * 100
                logger.info(f"  - í´ëŸ¬ìŠ¤í„° {label}: {count}ê°œ ({percentage:.2f}%)")
            
            return labels
            
        except Exception as e:
            logger.error(f"ë¼ë²¨ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def prepare_training_dataset(self, fused_features: np.ndarray, labels: np.ndarray) -> bool:
        """í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„"""
        try:
            logger.info("ğŸ“Š í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘")
            
            # ë°ì´í„° ë¶„í•  (70% í›ˆë ¨, 15% ê²€ì¦, 15% í…ŒìŠ¤íŠ¸)
            X_temp, X_test, y_temp, y_test = train_test_split(
                fused_features, labels, test_size=0.15, random_state=42, stratify=labels
            )
            
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp
            )
            
            logger.info(f"ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
            logger.info(f"  - í›ˆë ¨: {X_train.shape[0]}ê°œ ìƒ˜í”Œ")
            logger.info(f"  - ê²€ì¦: {X_val.shape[0]}ê°œ ìƒ˜í”Œ")
            logger.info(f"  - í…ŒìŠ¤íŠ¸: {X_test.shape[0]}ê°œ ìƒ˜í”Œ")
            
            # ë°ì´í„° ì €ì¥
            dataset_path = os.path.join(self.output_path, "fusion_dataset")
            os.makedirs(dataset_path, exist_ok=True)
            
            np.save(os.path.join(dataset_path, "train_features.npy"), X_train)
            np.save(os.path.join(dataset_path, "train_labels.npy"), y_train)
            np.save(os.path.join(dataset_path, "val_features.npy"), X_val)
            np.save(os.path.join(dataset_path, "val_labels.npy"), y_val)
            np.save(os.path.join(dataset_path, "test_features.npy"), X_test)
            np.save(os.path.join(dataset_path, "test_labels.npy"), y_test)
            
            # ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥
            dataset_info = {
                'total_samples': len(fused_features),
                'training_samples': len(X_train),
                'validation_samples': len(X_val),
                'test_samples': len(X_test),
                'feature_dimension': fused_features.shape[1],
                'created_at': datetime.now().isoformat(),
                'data_type': 'real_cmi_fusion',
                'description': 'ì‹¤ì œ CMI ë°ì´í„°ì™€ ì‹œë®¬ë ˆì´ì…˜ëœ ìŒì„± ë°ì´í„°ë¡œ ìƒì„±ëœ ìœµí•© ëª¨ë¸ í›ˆë ¨ ë°ì´í„°ì…‹'
            }
            
            with open(os.path.join(dataset_path, "dataset_info.json"), 'w', encoding='utf-8') as f:
                json.dump(dataset_info, f, indent=2, ensure_ascii=False)
            
            logger.info(f"í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {dataset_path}")
            return True
            
        except Exception as e:
            logger.error(f"í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return False
    
    def run_complete_pipeline(self) -> bool:
        """ì™„ì „í•œ ìœµí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # 1ë‹¨ê³„: CMI ë°ì´í„° ë¡œë“œ
            cmi_data = self.load_cmi_data()
            if cmi_data is None:
                return False
            
            # 2ë‹¨ê³„: CMI ë°ì´í„° êµ¬ì¡° ë¶„ì„
            analysis = self.analyze_cmi_data_structure(cmi_data)
            if not analysis:
                return False
            
            # 3ë‹¨ê³„: CMI íŠ¹ì§• ì¶”ì¶œ
            cmi_features = self.prepare_cmi_features(cmi_data, analysis)
            if cmi_features is None:
                return False
            
            # 4ë‹¨ê³„: ìŒì„± íŠ¹ì§• ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
            voice_features = self.create_voice_features_simulation(cmi_features.shape[0])
            if voice_features is None:
                return False
            
            # 5ë‹¨ê³„: íŠ¹ì§• ìœµí•©
            fused_features = self.fuse_features(cmi_features, voice_features)
            if fused_features is None:
                return False
            
            # 6ë‹¨ê³„: ë¼ë²¨ ìƒì„±
            labels = self.create_labels(cmi_data, analysis)
            if labels is None:
                return False
            
            # 7ë‹¨ê³„: í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„
            if not self.prepare_training_dataset(fused_features, labels):
                return False
            
            logger.info("ğŸ‰ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"ìœµí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        logger.info("ğŸ¯ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        pipeline = RealDataFusionPipeline()
        
        # ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        success = pipeline.run_complete_pipeline()
        
        if success:
            logger.info("ğŸ‰ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì„±ê³µ!")
            print("\n" + "="*60)
            print("ğŸ‰ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì„±ê³µ!")
            print("="*60)
            print("âœ… ì‹¤ì œ CMI ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ ì™„ë£Œ")
            print("âœ… CMI-ìŒì„± íŠ¹ì§• ìœµí•© ì™„ë£Œ")
            print("âœ… í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
            print("âœ… 'íŠ¸ìœˆ ì—”ì§„' ì‹¤ì œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì™„ë£Œ!")
            print("="*60)
        else:
            logger.error("âŒ ì‹¤ì œ ë°ì´í„° ìœµí•© íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
            print("\n" + "="*60)
            print("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ - ë¬¸ì œë¥¼ íŒŒì•…í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
            print("="*60)
        
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"\nâŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
