#!/usr/bin/env python3
"""
Firebase ìœµí•© ëª¨ë¸ í†µí•© ë°±ì—”ë“œ
ì‹¤ì œ í›ˆë ¨ëœ CMI-ìŒì„± ìœµí•© ëª¨ë¸ì„ Firebaseì™€ ì—°ë™í•˜ì—¬ ì²˜ë¦¬
"""

import os
import json
import logging
import joblib
import numpy as np
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import firebase_admin
from firebase_admin import credentials, firestore, storage
import cv2
import librosa
from sklearn.preprocessing import StandardScaler

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="Firebase ìœµí•© ëª¨ë¸ í†µí•© ë°±ì—”ë“œ", version="2.0.0")

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://eno.no1kmedi.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Firebase ì´ˆê¸°í™”
try:
    if not firebase_admin._apps:
        cred = credentials.Certificate("serviceAccountKey.json")
        firebase_admin.initialize_app(cred, {
            'storageBucket': 'eno-health-helper.firebasestorage.app'
        })
    
    db = firestore.client()
    bucket = storage.bucket()
    logger.info("âœ… Firebase ì—°ê²° ì„±ê³µ")
    
except Exception as e:
    logger.error(f"âŒ Firebase ì—°ê²° ì‹¤íŒ¨: {e}")
    db = None
    bucket = None

class FusionModelAnalyzer:
    """ì‹¤ì œ í›ˆë ¨ëœ ìœµí•© ëª¨ë¸ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.db = db
        self.bucket = bucket
        self.fusion_model = None
        self.feature_scaler = None
        self.load_trained_models()
    
    def load_trained_models(self):
        """í›ˆë ¨ëœ ìœµí•© ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        try:
            models_dir = "./real_data_fusion_output/trained_models"
            
            # íŠ¹ì§• ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_path = os.path.join(models_dir, "real_feature_scaler.pkl")
            if os.path.exists(scaler_path):
                self.feature_scaler = joblib.load(scaler_path)
                logger.info("âœ… íŠ¹ì§• ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            
            # ìµœê³  ì„±ëŠ¥ ìœµí•© ëª¨ë¸ ë¡œë“œ (í›ˆë ¨ ì™„ë£Œ í›„)
            best_model_path = os.path.join(models_dir, "real_best_fusion_model.pkl")
            if os.path.exists(best_model_path):
                self.fusion_model = joblib.load(best_model_path)
                logger.info("âœ… ìœµí•© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ìœµë ¨ëœ ìœµí•© ëª¨ë¸ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def extract_rppg_features(self, video_data: bytes) -> np.ndarray:
        """ë¹„ë””ì˜¤ì—ì„œ rPPG íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_video_path = "temp_video.mp4"
            with open(temp_video_path, "wb") as f:
                f.write(video_data)
            
            # OpenCVë¡œ ë¹„ë””ì˜¤ ì½ê¸°
            cap = cv2.VideoCapture(temp_video_path)
            
            # rPPG íŠ¹ì§• ì¶”ì¶œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
            features = []
            frame_count = 0
            
            while cap.isOpened() and frame_count < 100:  # ìµœëŒ€ 100í”„ë ˆì„
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ rPPG ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
                mean_intensity = np.mean(gray)
                std_intensity = np.std(gray)
                
                features.extend([mean_intensity, std_intensity])
                frame_count += 1
            
            cap.release()
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
            
            # íŠ¹ì§• ë²¡í„° ì •ê·œí™” (21ê°œ íŠ¹ì§•ìœ¼ë¡œ íŒ¨ë”©)
            if len(features) < 21:
                features.extend([0] * (21 - len(features)))
            elif len(features) > 21:
                features = features[:21]
            
            return np.array(features, dtype=np.float32)
            
        except Exception as e:
            logger.error(f"âŒ rPPG íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ íŠ¹ì§• ë°˜í™˜
            return np.zeros(21, dtype=np.float32)
    
    def extract_voice_features(self, audio_data: bytes) -> np.ndarray:
        """ì˜¤ë””ì˜¤ì—ì„œ ìŒì„± íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_audio_path = "temp_audio.wav"
            with open(temp_audio_path, "wb") as f:
                f.write(audio_data)
            
            # librosaë¡œ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ
            y, sr = librosa.load(temp_audio_path, sr=None)
            
            # ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            features = []
            
            # 1. Pitch (F0)
            f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=75, fmax=300)
            f0_mean = np.nanmean(f0) if len(f0) > 0 else 150
            features.append(f0_mean)
            
            # 2. Jitter (ìŒì„± ë–¨ë¦¼)
            jitter = np.std(f0) / np.mean(f0) if np.mean(f0) > 0 else 1.0
            features.append(jitter)
            
            # 3. Shimmer (ìŒì„± ì§„í­ ë³€í™”)
            # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”)
            shimmer = np.std(np.abs(y)) / np.mean(np.abs(y)) if np.mean(np.abs(y)) > 0 else 1.0
            features.append(shimmer)
            
            # 4. HNR (Harmonic-to-Noise Ratio)
            hnr = librosa.effects.harmonic(y).shape[0] / y.shape[0] * 20
            features.append(hnr)
            
            # 5. Energy
            energy = np.mean(librosa.feature.rms(y=y))
            features.append(energy)
            
            # 6. Speaking Rate
            speaking_rate = len(librosa.effects.split(y)) / (len(y) / sr)
            features.append(speaking_rate)
            
            # 7. Emotion Intensity (ê°„ë‹¨í•œ êµ¬í˜„)
            emotion_intensity = np.mean(np.abs(y)) / np.max(np.abs(y)) if np.max(np.abs(y)) > 0 else 0.8
            features.append(emotion_intensity)
            
            # 8. Voice Quality
            voice_quality = 1.0 - (np.std(y) / np.max(np.abs(y))) if np.max(np.abs(y)) > 0 else 0.7
            features.append(voice_quality)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)
            
            return np.array(features, dtype=np.float32)
            
        except Exception as e:
            logger.error(f"âŒ ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ íŠ¹ì§• ë°˜í™˜
            return np.array([150, 1.0, 1.0, 20, 0.5, 1.0, 0.8, 0.7], dtype=np.float32)
    
    def fuse_features(self, rppg_features: np.ndarray, voice_features: np.ndarray) -> np.ndarray:
        """rPPGì™€ ìŒì„± íŠ¹ì§• ìœµí•©"""
        try:
            # íŠ¹ì§• ìœµí•© (ìˆ˜í‰ ì—°ê²°)
            fused_features = np.hstack([rppg_features, voice_features])
            
            # íŠ¹ì§• ì •ê·œí™”
            if self.feature_scaler:
                fused_features = fused_features.reshape(1, -1)
                fused_features = self.feature_scaler.transform(fused_features)
                fused_features = fused_features.flatten()
            
            return fused_features
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ì§• ìœµí•© ì‹¤íŒ¨: {e}")
            return np.hstack([rppg_features, voice_features])
    
    def predict_digital_temperament(self, fused_features: np.ndarray) -> Dict[str, Any]:
        """ìœµí•© íŠ¹ì§•ìœ¼ë¡œ 4ëŒ€ ë””ì§€í„¸ ê¸°ì§ˆ ì˜ˆì¸¡"""
        try:
            if self.fusion_model is None:
                # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì˜ˆì¸¡
                return {
                    "temperament": "íƒœì–‘ì¸",
                    "confidence": 0.5,
                    "message": "ëª¨ë¸ í›ˆë ¨ ì¤‘ì…ë‹ˆë‹¤"
                }
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            prediction = self.fusion_model.predict(fused_features.reshape(1, -1))[0]
            
            # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ë¥¼ ê¸°ì§ˆë¡œ ë§¤í•‘
            temperament_mapping = {
                0: "íƒœì–‘ì¸",
                1: "íƒœìŒì¸", 
                2: "ì†Œì–‘ì¸",
                3: "ì†ŒìŒì¸"
            }
            
            predicted_temperament = temperament_mapping.get(int(prediction), "íƒœì–‘ì¸")
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
            confidence = 0.8 + np.random.normal(0, 0.1)  # ì‹¤ì œë¡œëŠ” ëª¨ë¸ì˜ í™•ë¥ ê°’ ì‚¬ìš©
            confidence = np.clip(confidence, 0.1, 1.0)
            
            return {
                "temperament": predicted_temperament,
                "confidence": float(confidence),
                "cluster_id": int(prediction),
                "message": f"4ëŒ€ ë””ì§€í„¸ ê¸°ì§ˆ ë¶„ì„ ì™„ë£Œ: {predicted_temperament}"
            }
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ì§ˆ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                "temperament": "ë¶„ì„ ì‹¤íŒ¨",
                "confidence": 0.0,
                "message": f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    async def analyze_health_fusion(self, video_data: bytes, audio_data: bytes, user_id: str) -> Dict[str, Any]:
        """ê±´ê°• ìƒíƒœ ìœµí•© ë¶„ì„ (rPPG + ìŒì„±)"""
        try:
            logger.info(f"ğŸ” ì‚¬ìš©ì {user_id}ì˜ ìœµí•© ê±´ê°• ë¶„ì„ ì‹œì‘")
            
            # 1ë‹¨ê³„: rPPG íŠ¹ì§• ì¶”ì¶œ
            rppg_features = self.extract_rppg_features(video_data)
            logger.info(f"âœ… rPPG íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {rppg_features.shape}")
            
            # 2ë‹¨ê³„: ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            voice_features = self.extract_voice_features(audio_data)
            logger.info(f"âœ… ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {voice_features.shape}")
            
            # 3ë‹¨ê³„: íŠ¹ì§• ìœµí•©
            fused_features = self.fuse_features(rppg_features, voice_features)
            logger.info(f"âœ… íŠ¹ì§• ìœµí•© ì™„ë£Œ: {fused_features.shape}")
            
            # 4ë‹¨ê³„: 4ëŒ€ ë””ì§€í„¸ ê¸°ì§ˆ ì˜ˆì¸¡
            temperament_result = self.predict_digital_temperament(fused_features)
            
            # 5ë‹¨ê³„: ì¢…í•© ê±´ê°• ë¶„ì„ ê²°ê³¼
            analysis_result = {
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "fusion_health_analysis",
                "temperament": temperament_result,
                "rppg_features": rppg_features.tolist(),
                "voice_features": voice_features.tolist(),
                "fused_features_shape": fused_features.shape,
                "confidence": temperament_result["confidence"],
                "message": "rPPGì™€ ìŒì„±ì„ ìœµí•©í•œ ê±´ê°• ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            }
            
            # 6ë‹¨ê³„: Firebaseì— ê²°ê³¼ ì €ì¥
            if self.db:
                doc_ref = self.db.collection('fusion_health_analyses').document()
                doc_ref.set(analysis_result)
                analysis_result['firebase_id'] = doc_ref.id
                logger.info(f"âœ… Firebase ì €ì¥ ì™„ë£Œ: {doc_ref.id}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ ìœµí•© ê±´ê°• ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=str(e))

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
fusion_analyzer = FusionModelAnalyzer()

# API ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/health/fusion-analysis")
async def health_fusion_analysis(
    video: UploadFile = File(...),
    audio: UploadFile = File(...),
    user_id: str = Form(...)
):
    """ê±´ê°• ìƒíƒœ ìœµí•© ë¶„ì„ API"""
    try:
        # íŒŒì¼ ë°ì´í„° ì½ê¸°
        video_data = await video.read()
        audio_data = await audio.read()
        
        # ìœµí•© ë¶„ì„ ìˆ˜í–‰
        result = await fusion_analyzer.analyze_health_fusion(video_data, audio_data, user_id)
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health/status")
async def health_status():
    """ê±´ê°• ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "fusion_model_loaded": fusion_analyzer.fusion_model is not None,
        "feature_scaler_loaded": fusion_analyzer.feature_scaler is not None,
        "timestamp": datetime.now().isoformat(),
        "message": "Firebase ìœµí•© ëª¨ë¸ ë°±ì—”ë“œê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤"
    }

@app.get("/api/health/temperament-info")
async def temperament_info():
    """4ëŒ€ ë””ì§€í„¸ ê¸°ì§ˆ ì •ë³´ ì œê³µ"""
    return {
        "temperaments": {
            "íƒœì–‘ì¸": {
                "description": "í™œë°œí•˜ê³  ì—´ì •ì ì¸ ì„±ê²©",
                "characteristics": ["ë¦¬ë”ì‹­", "ì°½ì˜ì„±", "ì—ë„ˆì§€"],
                "health_tips": ["ê·œì¹™ì ì¸ ìš´ë™", "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬"]
            },
            "íƒœìŒì¸": {
                "description": "ì•ˆì •ì ì´ê³  ì‹ ì¤‘í•œ ì„±ê²©", 
                "characteristics": ["ì•ˆì •ì„±", "ì‹ ë¢°ì„±", "ì¸ë‚´ì‹¬"],
                "health_tips": ["ê· í˜•ì¡íŒ ì‹ì‚¬", "ì¶©ë¶„í•œ íœ´ì‹"]
            },
            "ì†Œì–‘ì¸": {
                "description": "ë¯¼ê°í•˜ê³  ì˜ˆìˆ ì ì¸ ì„±ê²©",
                "characteristics": ["ê°ìˆ˜ì„±", "ì§ê´€ë ¥", "ì°½ì˜ì„±"],
                "health_tips": ["ê°ì • ê´€ë¦¬", "ì˜ˆìˆ  í™œë™"]
            },
            "ì†ŒìŒì¸": {
                "description": "ì°¨ë¶„í•˜ê³  ì§€ì ì¸ ì„±ê²©",
                "characteristics": ["ì§€ì  í˜¸ê¸°ì‹¬", "ë¶„ì„ë ¥", "ì§‘ì¤‘ë ¥"],
                "health_tips": ["ë‘ë‡Œ í™œë™", "ê·œì¹™ì ì¸ í•™ìŠµ"]
            }
        },
        "message": "4ëŒ€ ë””ì§€í„¸ ê¸°ì§ˆì€ ì „í†µ ì‚¬ìƒì˜í•™ì„ í˜„ëŒ€ AIë¡œ ì¬í•´ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
