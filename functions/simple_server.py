#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ HTTP ì„œë²„ - 'ìµœì¢… ì—°ê²°' API í…ŒìŠ¤íŠ¸ìš© + AI ì œí’ˆê´€ë¦¬
Node.js ì˜ì¡´ì„± ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ Pythonìœ¼ë¡œ êµ¬í˜„
"""

import json
import time
import uuid
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
import redis
import threading
from collections import Counter
import statistics

# Redis í´ë¼ì´ì–¸íŠ¸
try:
    redis_client = redis.Redis(host='redis', port=6379, decode_responses=True)
    redis_status = "connected"
except:
    redis_client = None
    redis_status = "disconnected"

# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì‹¤ì œë¡œëŠ” Firestore ì‚¬ìš©)
analysis_requests = {}
analysis_results = {}
user_feedback = []

class SimpleHTTPRequestHandler(BaseHTTPRequestHandler):
    
    def _set_headers(self, status_code=200):
        """CORS í—¤ë” ì„¤ì •"""
        self.send_response(status_code)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, Authorization')
        self.end_headers()
    
    def do_OPTIONS(self):
        """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
        self._set_headers(200)
    
    def do_GET(self):
        """GET ìš”ì²­ ì²˜ë¦¬"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path == '/healthCheck':
            self._handle_health_check()
        elif parsed_path.path == '/aiInsights':
            self._handle_get_ai_insights()
        else:
            self._set_headers(404)
            self.wfile.write(json.dumps({
                'error': 'Endpoint not found'
            }).encode())
    
    def do_POST(self):
        """POST ìš”ì²­ ì²˜ë¦¬"""
        parsed_path = urlparse(self.path)
        
        if parsed_path.path == '/requestAIAnalysis':
            self._handle_ai_analysis_request()
        elif parsed_path.path == '/getAnalysisResult':
            self._handle_get_analysis_result()
        elif parsed_path.path == '/getUserAnalysisHistory':
            self._handle_get_user_history()
        elif parsed_path.path == '/processAIAnalysis':
            self._handle_process_ai_analysis()
        elif parsed_path.path == '/submitFeedback':
            self._handle_submit_feedback()
        elif parsed_path.path == '/getFeedbackAnalytics':
            self._handle_get_feedback_analytics()
        else:
            self._set_headers(404)
            self.wfile.write(json.dumps({
                'error': 'Endpoint not found'
            }).encode())
    
    def _handle_health_check(self):
        """Health Check ì—”ë“œí¬ì¸íŠ¸"""
        self._set_headers(200)
        response = {
            'status': 'healthy',
            'message': 'Firebase Functions are running successfully.',
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            'services': {
                'firestore': 'simulated',
                'redis': redis_status,
                'authentication': 'simulated',
                'ai_agent': 'active'
            }
        }
        self.wfile.write(json.dumps(response, indent=2).encode())
    
    def _handle_ai_analysis_request(self):
        """AI ë¶„ì„ ìš”ì²­ ì²˜ë¦¬"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            user_id = data.get('userId')
            data_type = data.get('dataType')
            data_url = data.get('dataUrl')
            
            # í•„ìˆ˜ ë°ì´í„° ê²€ì¦
            if not all([user_id, data_type, data_url]):
                self._set_headers(400)
                self.wfile.write(json.dumps({
                    'error': 'Missing required data: userId, dataType, dataUrl'
                }).encode())
                return
            
            # ìš”ì²­ ID ìƒì„±
            request_id = f"analysis_{int(time.time())}_{str(uuid.uuid4())[:8]}"
            
            # ë¶„ì„ ìš”ì²­ ì •ë³´ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
            analysis_requests[request_id] = {
                'requestId': request_id,
                'userId': user_id,
                'dataType': data_type,
                'dataUrl': data_url,
                'status': 'pending',
                'createdAt': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'updatedAt': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
            }
            
            # Redisì— Pub/Sub ë©”ì‹œì§€ ë°œí–‰ (ë¹„ë™ê¸° ì²˜ë¦¬)
            if redis_client:
                message = {
                    'requestId': request_id,
                    'userId': user_id,
                    'dataType': data_type,
                    'dataUrl': data_url,
                    'timestamp': int(time.time())
                }
                redis_client.publish('ai-analysis-requests', json.dumps(message))
            
            # ë¡œê·¸ ê¸°ë¡
            print(f"AI analysis request submitted: {request_id}", {
                'userId': user_id,
                'dataType': data_type,
                'dataUrl': data_url
            })
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Analysis request submitted successfully.',
                'data': {
                    'requestId': request_id,
                    'status': 'pending',
                    'estimatedTime': '2-5 minutes'
                }
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in requestAIAnalysis: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())
    
    def _handle_get_analysis_result(self):
        """AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            request_id = data.get('requestId')
            
            if not request_id:
                self._set_headers(400)
                self.wfile.write(json.dumps({
                    'error': 'Missing requestId'
                }).encode())
                return
            
            # ë©”ëª¨ë¦¬ì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
            result = analysis_results.get(request_id)
            
            if not result:
                self._set_headers(200)
                response = {
                    'status': 'pending',
                    'message': 'Analysis is still in progress.',
                    'data': None
                }
                self.wfile.write(json.dumps(response, indent=2).encode())
                return
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Analysis result retrieved successfully.',
                'data': result
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in getAnalysisResult: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())
    
    def _handle_get_user_history(self):
        """ì‚¬ìš©ì ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            user_id = data.get('userId')
            limit = data.get('limit', 10)
            
            if not user_id:
                self._set_headers(400)
                self.wfile.write(json.dumps({
                    'error': 'Missing userId'
                }).encode())
                return
            
            # ë©”ëª¨ë¦¬ì—ì„œ ì‚¬ìš©ìì˜ ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            history = [
                request for request in analysis_requests.values()
                if request['userId'] == user_id
            ]
            
            # ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ì œí•œ
            history.sort(key=lambda x: x['createdAt'], reverse=True)
            history = history[:limit]
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Analysis history retrieved successfully.',
                'data': {
                    'history': history,
                    'total': len(history)
                }
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in getUserAnalysisHistory: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())
    
    def _handle_process_ai_analysis(self):
        """AI ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (AI ì—”ì§„ ì—°ë™ìš©)"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            request_id = data.get('requestId')
            results = data.get('results')
            
            if not all([request_id, results]):
                self._set_headers(400)
                self.wfile.write(json.dumps({
                    'error': 'Missing required data: requestId, results'
                }).encode())
                return
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
            analysis_results[request_id] = {
                'requestId': request_id,
                'results': results,
                'completedAt': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'status': 'completed'
            }
            
            # ì›ë³¸ ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
            if request_id in analysis_requests:
                analysis_requests[request_id]['status'] = 'completed'
                analysis_requests[request_id]['updatedAt'] = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
            
            print(f"AI analysis completed: {request_id}", results)
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Analysis result saved successfully.'
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in processAIAnalysis: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())

    def _handle_submit_feedback(self):
        """ì‚¬ìš©ì í”¼ë“œë°± ì œì¶œ"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            feedback_data = json.loads(post_data.decode('utf-8'))
            
            # í•„ìˆ˜ ë°ì´í„° ê²€ì¦
            required_fields = ['type', 'priority', 'category', 'title', 'description', 'rating']
            if not all(field in feedback_data for field in required_fields):
                self._set_headers(400)
                self.wfile.write(json.dumps({
                    'error': 'Missing required feedback fields'
                }).encode())
                return
            
            # í”¼ë“œë°± ID ìƒì„±
            feedback_id = f"feedback_{int(time.time())}_{str(uuid.uuid4())[:8]}"
            feedback_data['id'] = feedback_id
            feedback_data['timestamp'] = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
            
            # ë©”ëª¨ë¦¬ì— í”¼ë“œë°± ì €ì¥
            user_feedback.append(feedback_data)
            
            # Redisì— í”¼ë“œë°± ì €ì¥ (ì‹¤ì œë¡œëŠ” Firestore ì‚¬ìš©)
            if redis_client:
                redis_client.set(f"feedback:{feedback_id}", json.dumps(feedback_data))
            
            print(f"Feedback submitted: {feedback_id}", feedback_data)
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Feedback submitted successfully.',
                'data': {
                    'feedbackId': feedback_id,
                    'timestamp': feedback_data['timestamp']
                }
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in submitFeedback: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())

    def _handle_get_feedback_analytics(self):
        """í”¼ë“œë°± ë¶„ì„ ë°ì´í„° ì¡°íšŒ"""
        try:
            if not user_feedback:
                self._set_headers(200)
                response = {
                    'status': 'success',
                    'message': 'No feedback data available.',
                    'data': {
                        'totalFeedback': 0,
                        'analytics': {}
                    }
                }
                self.wfile.write(json.dumps(response, indent=2).encode())
                return
            
            # AI ì—ì´ì „íŠ¸ê°€ í”¼ë“œë°± ë¶„ì„
            analytics = self._analyze_feedback_with_ai()
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'Feedback analytics generated successfully.',
                'data': {
                    'totalFeedback': len(user_feedback),
                    'analytics': analytics
                }
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in getFeedbackAnalytics: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())

    def _handle_get_ai_insights(self):
        """AI ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ"""
        try:
            if not user_feedback:
                insights = self._generate_default_insights()
            else:
                insights = self._analyze_feedback_with_ai()
            
            self._set_headers(200)
            response = {
                'status': 'success',
                'message': 'AI insights generated successfully.',
                'data': insights
            }
            self.wfile.write(json.dumps(response, indent=2).encode())
            
        except Exception as e:
            print(f"Error in getAIInsights: {e}")
            self._set_headers(500)
            self.wfile.write(json.dumps({
                'error': 'Internal server error occurred.'
            }).encode())

    def _analyze_feedback_with_ai(self):
        """AI ì—ì´ì „íŠ¸ê°€ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            # ê¸°ë³¸ í†µê³„ ê³„ì‚°
            total_feedback = len(user_feedback)
            ratings = [f['rating'] for f in user_feedback]
            average_rating = statistics.mean(ratings) if ratings else 0
            
            # í”¼ë“œë°± ìœ í˜•ë³„ ë¶„ì„
            feedback_types = Counter([f['type'] for f in user_feedback])
            feedback_categories = Counter([f['category'] for f in user_feedback])
            feedback_priorities = Counter([f['priority'] for f in user_feedback])
            
            # AI ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ë¶„ì„
            priority_scores = {
                'bug': 10,
                'feature': 7,
                'improvement': 5,
                'experience': 3
            }
            
            weighted_priorities = {}
            for feedback in user_feedback:
                feedback_type = feedback['type']
                priority = feedback['priority']
                priority_weight = priority_scores.get(feedback_type, 1)
                
                if priority not in weighted_priorities:
                    weighted_priorities[priority] = 0
                weighted_priorities[priority] += priority_weight
            
            # AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = {
                'summary': {
                    'totalFeedback': total_feedback,
                    'averageRating': round(average_rating, 1),
                    'mostCommonType': feedback_types.most_common(1)[0][0] if feedback_types else 'N/A',
                    'mostCommonCategory': feedback_categories.most_common(1)[0][0] if feedback_categories else 'N/A'
                },
                'trends': {
                    'feedbackTypes': dict(feedback_types),
                    'categories': dict(feedback_categories),
                    'priorities': dict(feedback_priorities)
                },
                'recommendations': self._generate_ai_recommendations(
                    feedback_types, feedback_categories, average_rating
                ),
                'actionItems': self._generate_action_items(weighted_priorities, feedback_types)
            }
            
            return insights
            
        except Exception as e:
            print(f"Error in AI feedback analysis: {e}")
            return self._generate_default_insights()

    def _generate_ai_recommendations(self, feedback_types, feedback_categories, average_rating):
        """AI ê¸°ë°˜ ì œí’ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë²„ê·¸ ë¦¬í¬íŠ¸ê°€ ë§ìœ¼ë©´ ì•ˆì •ì„± ê°œì„  ê¶Œì¥
        if feedback_types.get('bug', 0) > 0:
            recommendations.append({
                'priority': 'high',
                'category': 'stability',
                'title': 'ë²„ê·¸ ìˆ˜ì • ë° ì•ˆì •ì„± í–¥ìƒ',
                'description': f'ë²„ê·¸ ë¦¬í¬íŠ¸ {feedback_types["bug"]}ê±´ì´ ë³´ê³ ë˜ì–´ ì¦‰ì‹œ ì•ˆì •ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'impact': 'ì‚¬ìš©ì ê²½í—˜ ë° ì œí’ˆ ì‹ ë¢°ë„ í–¥ìƒ'
            })
        
        # ê¸°ëŠ¥ ìš”ì²­ì´ ë§ìœ¼ë©´ ì‹ ê·œ ê¸°ëŠ¥ ê°œë°œ ê¶Œì¥
        if feedback_types.get('feature', 0) > 0:
            recommendations.append({
                'priority': 'medium',
                'category': 'development',
                'title': 'ì‚¬ìš©ì ìš”ì²­ ê¸°ëŠ¥ ê°œë°œ',
                'description': f'ê¸°ëŠ¥ ìš”ì²­ {feedback_types["feature"]}ê±´ì´ ìˆì–´ ì‚¬ìš©ì ë§Œì¡±ë„ í–¥ìƒ ê¸°íšŒì…ë‹ˆë‹¤.',
                'impact': 'ì‚¬ìš©ì ë§Œì¡±ë„ ë° ì œí’ˆ ê²½ìŸë ¥ í–¥ìƒ'
            })
        
        # í‰ê·  ë§Œì¡±ë„ê°€ ë‚®ìœ¼ë©´ ì „ë°˜ì  ê°œì„  ê¶Œì¥
        if average_rating < 3.5:
            recommendations.append({
                'priority': 'high',
                'category': 'overall',
                'title': 'ì „ë°˜ì  ì‚¬ìš©ì ê²½í—˜ ê°œì„ ',
                'description': f'í‰ê·  ë§Œì¡±ë„ {average_rating}/5.0ìœ¼ë¡œ ì „ë°˜ì  ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'impact': 'ì‚¬ìš©ì ìœ ì§€ìœ¨ ë° ì œí’ˆ ì¸ì§€ë„ í–¥ìƒ'
            })
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê°œì„  ê¶Œì¥ì‚¬í•­
        if feedback_categories.get('ui', 0) > 0:
            recommendations.append({
                'priority': 'medium',
                'category': 'ui',
                'title': 'ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œì„ ',
                'description': 'UI ê´€ë ¨ í”¼ë“œë°±ì´ ìˆì–´ ì‚¬ìš©ì„± í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'impact': 'ì‚¬ìš©ì ì ‘ê·¼ì„± ë° ì‘ì—… íš¨ìœ¨ì„± í–¥ìƒ'
            })
        
        return recommendations

    def _generate_action_items(self, weighted_priorities, feedback_types):
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        action_items = []
        
        # ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜ ì•„ì´í…œ
        for priority, weight in sorted(weighted_priorities.items(), key=lambda x: x[1], reverse=True):
            if priority == 'critical':
                action_items.append({
                    'priority': 'critical',
                    'action': 'ì¦‰ì‹œ ì¡°ì¹˜',
                    'description': 'ê¸´ê¸‰í•œ ë¬¸ì œë¥¼ ìš°ì„ ì ìœ¼ë¡œ í•´ê²°',
                    'timeline': '24ì‹œê°„ ì´ë‚´'
                })
            elif priority == 'high':
                action_items.append({
                    'priority': 'high',
                    'action': 'ë¹ ë¥¸ ì¡°ì¹˜',
                    'description': 'ë†’ì€ ìš°ì„ ìˆœìœ„ ë¬¸ì œë¥¼ ì‹ ì†í•˜ê²Œ í•´ê²°',
                    'timeline': '1ì£¼ì¼ ì´ë‚´'
                })
        
        # í”¼ë“œë°± ìœ í˜•ë³„ ì•¡ì…˜ ì•„ì´í…œ
        if feedback_types.get('bug', 0) > 0:
            action_items.append({
                'priority': 'high',
                'action': 'ë²„ê·¸ ìˆ˜ì •',
                'description': 'ì‚¬ìš©ìë“¤ì´ ë³´ê³ í•œ ë²„ê·¸ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì •',
                'timeline': '2ì£¼ì¼ ì´ë‚´'
            })
        
        if feedback_types.get('feature', 0) > 0:
            action_items.append({
                'priority': 'medium',
                'action': 'ê¸°ëŠ¥ ê°œë°œ ê³„íš',
                'description': 'ì‚¬ìš©ì ìš”ì²­ ê¸°ëŠ¥ë“¤ì˜ ê°œë°œ ë¡œë“œë§µ ìˆ˜ë¦½',
                'timeline': '1ê°œì›” ì´ë‚´'
            })
        
        return action_items

    def _generate_default_insights(self):
        """ê¸°ë³¸ AI ì¸ì‚¬ì´íŠ¸ ìƒì„± (í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ì„ ë•Œ)"""
        return {
            'summary': {
                'totalFeedback': 0,
                'averageRating': 0,
                'mostCommonType': 'N/A',
                'mostCommonCategory': 'N/A'
            },
            'trends': {
                'feedbackTypes': {},
                'categories': {},
                'priorities': {}
            },
            'recommendations': [
                {
                    'priority': 'medium',
                    'category': 'onboarding',
                    'title': 'ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì‹œì‘',
                    'description': 'ì œí’ˆ ê°œì„ ì„ ìœ„í•œ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ì„ ì‹œì‘í•˜ì„¸ìš”.',
                    'impact': 'ë°ì´í„° ê¸°ë°˜ ì œí’ˆ ê°œë°œ ê¸°ë°˜ ë§ˆë ¨'
                }
            ],
            'actionItems': [
                {
                    'priority': 'medium',
                    'action': 'í”¼ë“œë°± ì‹œìŠ¤í…œ í™œì„±í™”',
                    'description': 'ì‚¬ìš©ìë“¤ì´ ì‰½ê²Œ í”¼ë“œë°±ì„ ì œì¶œí•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ êµ¬ì¶•',
                    'timeline': '1ì£¼ì¼ ì´ë‚´'
                }
            ]
        }

def run_server(port=5001):
    """ì„œë²„ ì‹¤í–‰"""
    server_address = ('', port)
    httpd = HTTPServer(server_address, SimpleHTTPRequestHandler)
    print(f"ï¿½ï¿½ Firebase Functions ì„œë²„ê°€ í¬íŠ¸ {port}ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
    print(f"ğŸ“¡ Redis ì—°ê²° ìƒíƒœ: {redis_status}")
    print(f"ğŸ”— Health Check: http://localhost:{port}/healthCheck")
    print(f"ğŸ¤– AI ì œí’ˆê´€ë¦¬ ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    httpd.serve_forever()

if __name__ == '__main__':
    run_server() 