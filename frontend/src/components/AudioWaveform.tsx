'use client';

import React, { useRef, useEffect, useState, useCallback } from 'react';
import { motion } from 'framer-motion';

interface AudioWaveformProps {
  isRecording: boolean;
  audioData?: Float32Array;
  onWaveformUpdate?: (data: Float32Array) => void;
  width?: number;
  height?: number;
}

export default function AudioWaveform({ 
  isRecording, 
  audioData, 
  onWaveformUpdate,
  width = 400, 
  height = 200 
}: AudioWaveformProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  
  const [isInitialized, setIsInitialized] = useState(false);
  const [error, setError] = useState<string | null>(null);

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
  const initializeAudio = useCallback(async () => {
    try {
      if (audioContextRef.current) return;

      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      
      // ë¶„ì„ê¸° ì„¤ì •
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      analyser.minDecibels = -90;
      analyser.maxDecibels = -10;
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100,
          channelCount: 1
        }
      });
      
      streamRef.current = stream;
      const microphone = audioContext.createMediaStreamSource(stream);
      microphone.connect(analyser);
      microphoneRef.current = microphone;
      
      setIsInitialized(true);
      setError(null);
      
    } catch (err) {
      console.error('Audio initialization error:', err);
      setError('ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  }, []);

  // ì˜¤ë””ì˜¤ íŒŒí˜• ê·¸ë¦¬ê¸°
  const drawWaveform = useCallback(() => {
    if (!canvasRef.current || !analyserRef.current || !isRecording) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const analyser = analyserRef.current;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const floatArray = new Float32Array(bufferLength);

    // ì£¼íŒŒìˆ˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    analyser.getByteFrequencyData(dataArray);
    
    // Float32Arrayë¡œ ë³€í™˜ (0-1 ë²”ìœ„)
    for (let i = 0; i < bufferLength; i++) {
      floatArray[i] = dataArray[i] / 255;
    }

    // onWaveformUpdate ì½œë°± í˜¸ì¶œ
    if (onWaveformUpdate) {
      onWaveformUpdate(floatArray);
    }

    // ìº”ë²„ìŠ¤ í´ë¦¬ì–´
    ctx.clearRect(0, 0, width, height);

    // ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½
    const gradient = ctx.createLinearGradient(0, 0, 0, height);
    gradient.addColorStop(0, 'rgba(34, 197, 94, 0.1)');
    gradient.addColorStop(1, 'rgba(59, 130, 246, 0.1)');
    
    ctx.fillStyle = gradient;
    ctx.fillRect(0, 0, width, height);

    // íŒŒí˜• ê·¸ë¦¬ê¸°
    const barWidth = (width / bufferLength) * 2.5;
    let barHeight;
    let x = 0;

    ctx.fillStyle = 'rgba(34, 197, 94, 0.8)';
    ctx.strokeStyle = 'rgba(34, 197, 94, 1)';
    ctx.lineWidth = 2;

    for (let i = 0; i < bufferLength; i++) {
      barHeight = (floatArray[i] * height) / 2;

      // ì¤‘ì•™ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì•„ë˜ë¡œ ê·¸ë¦¬ê¸°
      const y1 = height / 2 - barHeight;
      const y2 = height / 2 + barHeight;

      // ê·¸ë¼ë””ì–¸íŠ¸ íš¨ê³¼
      const barGradient = ctx.createLinearGradient(x, y1, x, y2);
      barGradient.addColorStop(0, 'rgba(34, 197, 94, 0.8)');
      barGradient.addColorStop(0.5, 'rgba(59, 130, 246, 0.8)');
      barGradient.addColorStop(1, 'rgba(34, 197, 94, 0.8)');

      ctx.fillStyle = barGradient;
      ctx.fillRect(x, y1, barWidth, barHeight * 2);

      // í…Œë‘ë¦¬
      ctx.strokeRect(x, y1, barWidth, barHeight * 2);

      x += barWidth + 1;
    }

    // ì‹¤ì‹œê°„ íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜
    if (isRecording) {
      animationFrameRef.current = requestAnimationFrame(drawWaveform);
    }
  }, [isRecording, width, height, onWaveformUpdate]);

  // ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ì²˜ë¦¬
  useEffect(() => {
    if (isRecording && isInitialized) {
      drawWaveform();
    } else if (!isRecording && animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
  }, [isRecording, isInitialized, drawWaveform]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
  useEffect(() => {
    if (isRecording && !isInitialized) {
      initializeAudio();
    }
  }, [isRecording, isInitialized, initializeAudio]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  // ì™¸ë¶€ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš° ì²˜ë¦¬
  useEffect(() => {
    if (audioData && canvasRef.current) {
      const canvas = canvasRef.current;
      const ctx = canvas.getContext('2d');
      if (!ctx) return;

      ctx.clearRect(0, 0, width, height);

      // ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½
      const gradient = ctx.createLinearGradient(0, 0, 0, height);
      gradient.addColorStop(0, 'rgba(34, 197, 94, 0.1)');
      gradient.addColorStop(1, 'rgba(59, 130, 246, 0.1)');
      
      ctx.fillStyle = gradient;
      ctx.fillRect(0, 0, width, height);

      // ì •ì  íŒŒí˜• ê·¸ë¦¬ê¸°
      const barWidth = (width / audioData.length) * 2.5;
      let x = 0;

      ctx.fillStyle = 'rgba(34, 197, 94, 0.8)';
      ctx.strokeStyle = 'rgba(34, 197, 94, 1)';
      ctx.lineWidth = 2;

      for (let i = 0; i < audioData.length; i++) {
        const barHeight = (audioData[i] * height) / 2;
        const y1 = height / 2 - barHeight;
        const y2 = height / 2 + barHeight;

        // ê·¸ë¼ë””ì–¸íŠ¸ íš¨ê³¼
        const barGradient = ctx.createLinearGradient(x, y1, x, y2);
        barGradient.addColorStop(0, 'rgba(34, 197, 94, 0.8)');
        barGradient.addColorStop(0.5, 'rgba(59, 130, 246, 0.8)');
        barGradient.addColorStop(1, 'rgba(34, 197, 94, 0.8)');

        ctx.fillStyle = barGradient;
        ctx.fillRect(x, y1, barWidth, barHeight * 2);

        // í…Œë‘ë¦¬
        ctx.strokeRect(x, y1, barWidth, barHeight * 2);

        x += barWidth + 1;
      }
    }
  }, [audioData, width, height]);

  return (
    <div className="w-full">
      <div className="mb-4 text-center">
        <h3 className="text-lg font-semibold text-white mb-2">
          {isRecording ? 'ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± íŒŒí˜•' : 'ğŸ“Š ìŒì„± íŒŒí˜• ì‹œê°í™”'}
        </h3>
        <p className="text-sm text-gray-300">
          {isRecording ? 'ë§ˆì´í¬ ì…ë ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤' : 'ì¸¡ì •ëœ ìŒì„± ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤'}
        </p>
      </div>

      <div className="relative">
        <canvas
          ref={canvasRef}
          width={width}
          height={height}
          className="w-full h-auto rounded-lg border border-cyan-500/30 bg-gray-900"
        />
        
        {/* ë…¹ìŒ ìƒíƒœ í‘œì‹œ */}
        {isRecording && (
          <motion.div
            initial={{ opacity: 0, scale: 0.8 }}
            animate={{ opacity: 1, scale: 1 }}
            className="absolute top-4 right-4"
          >
            <div className="flex items-center space-x-2 bg-red-500/20 border border-red-500/50 rounded-full px-3 py-1">
              <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
              <span className="text-red-400 text-xs font-medium">ë…¹ìŒ ì¤‘</span>
            </div>
          </motion.div>
        )}

        {/* ì˜¤ë””ì˜¤ ë ˆë²¨ ë¯¸í„° */}
        {isRecording && (
          <div className="absolute bottom-4 left-4 right-4">
            <div className="bg-gray-800/50 rounded-full h-2 overflow-hidden">
              <motion.div
                className="h-full bg-gradient-to-r from-green-400 to-blue-500"
                initial={{ width: '0%' }}
                animate={{ width: '60%' }}
                transition={{ duration: 0.5, repeat: Infinity, repeatType: 'reverse' }}
              />
            </div>
          </div>
        )}
      </div>

      {/* ì˜¤ë¥˜ ë©”ì‹œì§€ */}
      {error && (
        <div className="mt-4 p-3 bg-red-900/30 border border-red-500/50 rounded-lg">
          <p className="text-red-400 text-sm text-center">{error}</p>
        </div>
      )}

      {/* ìƒíƒœ ì •ë³´ */}
      <div className="mt-4 text-center text-sm text-gray-400">
        {isRecording ? (
          <div className="flex items-center justify-center space-x-4">
            <span>ğŸµ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§</span>
            <span>ğŸ“Š FFT í¬ê¸°: 2048</span>
            <span>ğŸ¤ ìƒ˜í”Œë ˆì´íŠ¸: 44.1kHz</span>
          </div>
        ) : (
          <div className="flex items-center justify-center space-x-4">
            <span>â¸ï¸ ëŒ€ê¸° ì¤‘</span>
            <span>ğŸ“± ë§ˆì´í¬ ê¶Œí•œ í•„ìš”</span>
          </div>
        )}
      </div>
    </div>
  );
}
