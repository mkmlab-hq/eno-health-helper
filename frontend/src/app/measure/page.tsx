'use client';

import { useState, useRef, useCallback, useEffect } from 'react';
import { useRouter } from 'next/navigation';
import { Camera, Mic, Activity } from 'lucide-react';

interface HealthResult {
  rppg_result: {
    heart_rate: number;
    hrv: number;
    stress_level: string;
    confidence: number;
  };
  voice_result: {
    f0: number;
    jitter: number;
    shimmer: number;
    hnr: number;
    confidence: number;
  };
  health_score: number;
  measurement_id: string;
}

export default function MeasurePage() {
  const [isMeasuring, setIsMeasuring] = useState(false);
  const [elapsedTime, setElapsedTime] = useState(0);
  const [currentPhase, setCurrentPhase] = useState<'ready' | 'face' | 'voice' | 'complete'>('ready');
  const [error, setError] = useState<string | null>(null);
  const [healthResult, setHealthResult] = useState<HealthResult | null>(null);
  const [showConsentModal, setShowConsentModal] = useState(false);
  const [privacyConsent, setPrivacyConsent] = useState({ requiredConsent: false, optionalConsent: false });
  
  // ì‹¤ì œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ê´€ë ¨ ìƒíƒœ
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [isMicrophoneReady, setIsMicrophoneReady] = useState(false);
  
  const router = useRouter();
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const measurementIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  
  // ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ìš©
  const videoFramesRef = useRef<ImageData[]>([]);
  const audioChunksRef = useRef<Blob[]>([]);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);

  const TOTAL_DURATION = 35;
  const FACE_SCAN_DURATION = 30;  // 30ì´ˆ ì–¼êµ´ ìŠ¤ìº”
  const VOICE_SCAN_DURATION = 5;  // 5ì´ˆ ìŒì„± ì¸¡ì •

  // ì¹´ë©”ë¼ ì´ˆê¸°í™”
  const initializeCamera = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: 640,
          height: 480,
          frameRate: 30
        }
      });
      
      setVideoStream(stream);
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.onloadedmetadata = () => {
          setIsCameraReady(true);
        };
      }
    } catch (err) {
      setError('ì¹´ë©”ë¼ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      console.error('Camera error:', err);
    }
  }, []);

  // ë§ˆì´í¬ ì´ˆê¸°í™”
  const initializeMicrophone = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });
      
      setAudioStream(stream);
      setIsMicrophoneReady(true);
    } catch (err) {
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      console.error('Microphone error:', err);
    }
  }, []);

  // ë¹„ë””ì˜¤ í”„ë ˆì„ ìº¡ì²˜
  const captureVideoFrame = useCallback(() => {
    if (!videoRef.current || !canvasRef.current) return;
    
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    canvas.width = videoRef.current.videoWidth;
    canvas.height = videoRef.current.videoHeight;
    ctx.drawImage(videoRef.current, 0, 0);
    
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    videoFramesRef.current.push(imageData);
  }, []);

  // ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘
  const startAudioRecording = useCallback(() => {
    if (!audioStream) return;
    
    const mediaRecorder = new MediaRecorder(audioStream, {
      mimeType: 'audio/webm;codecs=opus'
    });
    
    mediaRecorderRef.current = mediaRecorder;
    audioChunksRef.current = [];
    
    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunksRef.current.push(event.data);
      }
    };
    
    mediaRecorder.start(100); // 100msë§ˆë‹¤ ì²­í¬ ìˆ˜ì§‘
  }, [audioStream]);

  // ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
  const stopAudioRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
  }, []);

  // rPPG ë¶„ì„ API í˜¸ì¶œ
  const analyzeRPPG = useCallback(async (frames: ImageData[]) => {
    try {
      // í”„ë ˆì„ì„ base64ë¡œ ë³€í™˜
      const frameData = frames.map(frame => {
        const canvas = document.createElement('canvas');
        canvas.width = frame.width;
        canvas.height = frame.height;
        const ctx = canvas.getContext('2d');
        ctx?.putImageData(frame, 0, 0);
        return canvas.toDataURL('image/jpeg', 0.8);
      });

      const response = await fetch('http://localhost:8000/api/rppg/analyze', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          frames: frameData,
          frame_rate: 30
        })
      });

      if (!response.ok) {
        throw new Error('rPPG ë¶„ì„ ì‹¤íŒ¨');
      }

      return await response.json();
    } catch (err) {
      console.error('rPPG analysis error:', err);
      throw err;
    }
  }, []);

  // ìŒì„± ë¶„ì„ API í˜¸ì¶œ
  const analyzeVoice = useCallback(async (audioBlob: Blob) => {
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'voice_recording.webm');

      const response = await fetch('http://localhost:8000/api/voice/analyze', {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        throw new Error('ìŒì„± ë¶„ì„ ì‹¤íŒ¨');
      }

      return await response.json();
    } catch (err) {
      console.error('Voice analysis error:', err);
      throw err;
    }
  }, []);

  // ê±´ê°• ì ìˆ˜ ê³„ì‚° API í˜¸ì¶œ
  const calculateHealthScore = useCallback(async (rppgData: any, voiceData: any) => {
    try {
      const response = await fetch('http://localhost:8000/api/health/calculate-score', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          rppg_result: rppgData,
          voice_result: voiceData
        })
      });

      if (!response.ok) {
        throw new Error('ê±´ê°• ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨');
      }

      return await response.json();
    } catch (err) {
      console.error('Health score calculation error:', err);
      throw err;
    }
  }, []);

  // ì‹¤ì œ ì¸¡ì • ì‹œì‘
  const startMeasurement = useCallback(async () => {
    try {
      setIsMeasuring(true);
      setElapsedTime(0);
      setCurrentPhase('face');
      setError(null);
      
      // ë°ì´í„° ì´ˆê¸°í™”
      videoFramesRef.current = [];
      audioChunksRef.current = [];

      // ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ì´ˆê¸°í™”
      await initializeCamera();
      await initializeMicrophone();

      measurementIntervalRef.current = setInterval(() => {
        setElapsedTime(prev => {
          const newTime = prev + 1;
          
          if (newTime <= FACE_SCAN_DURATION) {
            setCurrentPhase('face');
            // ì–¼êµ´ í”„ë ˆì„ ìº¡ì²˜
            captureVideoFrame();
          } else if (newTime <= TOTAL_DURATION) {
            if (newTime === FACE_SCAN_DURATION + 1) {
              setCurrentPhase('voice');
              // ìŒì„± ë…¹ìŒ ì‹œì‘
              startAudioRecording();
            }
          } else {
            setCurrentPhase('complete');
            return prev;
          }
          
          return newTime;
        });
      }, 1000);
    } catch (err) {
      setError('ì¸¡ì • ì‹œì‘ ì‹¤íŒ¨: ' + (err as Error).message);
      setIsMeasuring(false);
    }
  }, [initializeCamera, initializeMicrophone, captureVideoFrame, startAudioRecording]);

  // ì¸¡ì • ì™„ë£Œ ë° ê²°ê³¼ ë¶„ì„
  const finishMeasurement = useCallback(async () => {
    try {
      if (measurementIntervalRef.current) {
        clearInterval(measurementIntervalRef.current);
        measurementIntervalRef.current = null;
      }

      // ìŒì„± ë…¹ìŒ ì¤‘ì§€
      stopAudioRecording();

      // ê²°ê³¼ ë¶„ì„
      const rppgResult = await analyzeRPPG(videoFramesRef.current);
      const voiceResult = await analyzeVoice(new Blob(audioChunksRef.current));
      const healthScore = await calculateHealthScore(rppgResult, voiceResult);

      setHealthResult({
        rppg_result: rppgResult,
        voice_result: voiceResult,
        health_score: healthScore.health_score,
        measurement_id: healthScore.measurement_id
      });

      setIsMeasuring(false);
      setCurrentPhase('complete');
    } catch (err) {
      setError('ì¸¡ì • ì™„ë£Œ ì‹¤íŒ¨: ' + (err as Error).message);
      setIsMeasuring(false);
    }
  }, [stopAudioRecording, analyzeRPPG, analyzeVoice, calculateHealthScore]);

  const resetMeasurement = useCallback(() => {
    setIsMeasuring(false);
    setElapsedTime(0);
    setCurrentPhase('ready');
    setError(null);
    setHealthResult(null);
    
    // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (videoStream) {
      videoStream.getTracks().forEach(track => track.stop());
      setVideoStream(null);
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => track.stop());
      setAudioStream(null);
    }
    
    setIsCameraReady(false);
    setIsMicrophoneReady(false);
    
    if (measurementIntervalRef.current) {
      clearInterval(measurementIntervalRef.current);
      measurementIntervalRef.current = null;
    }
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
  }, [videoStream, audioStream]);

  const goToResults = useCallback(() => {
    router.push('/result');
  }, [router]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (measurementIntervalRef.current) {
        clearInterval(measurementIntervalRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
      }
    };
  }, [videoStream, audioStream]);

  // ìë™ ì™„ë£Œ
  useEffect(() => {
    if (elapsedTime >= TOTAL_DURATION) {
      finishMeasurement();
    }
  }, [elapsedTime, finishMeasurement]);

  const progress = (elapsedTime / TOTAL_DURATION) * 100;

  return (
    <div className="min-h-screen bg-gradient-to-br from-gray-900 via-blue-900 to-gray-900 flex items-center justify-center p-4">
      <div className="w-full max-w-md mx-auto">
        <div className="glass-card rounded-2xl p-6 text-center">
          
          {/* Header */}
          <div className="mb-4">
            <h1 className="text-2xl font-orbitron font-bold text-neon-cyan mb-2">ì—”ì˜¤ê±´ê°•ë„ìš°ë¯¸</h1>
            <p className="text-gray-300 text-sm">ì•ˆë…•í•˜ì„¸ìš”, ê²ŒìŠ¤íŠ¸ë‹˜</p>
          </div>

          {/* Status Display */}
          <div className="mb-4">
            <h2 id="status-title" className="text-2xl font-bold text-neon-cyan neon-glow">
              {currentPhase === 'ready' && 'ê±´ê°• ì¸¡ì • ì¤€ë¹„'}
              {currentPhase === 'face' && 'ì–¼êµ´ ë¶„ì„ ì¤‘'}
              {currentPhase === 'voice' && 'ìŒì„± ë¶„ì„ ì¤‘'}
              {currentPhase === 'complete' && 'ë¶„ì„ ì™„ë£Œ!'}
            </h2>
            <p id="status-instruction" className="text-gray-300 mt-1">
              {currentPhase === 'ready' && 'ì¸¡ì •ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.'}
              {currentPhase === 'face' && `ê°€ì´ë“œë¼ì¸ì— ì–¼êµ´ì„ ë§ì¶°ì£¼ì„¸ìš”. (${FACE_SCAN_DURATION - elapsedTime}ì´ˆ)`}
              {currentPhase === 'voice' && `í¸ì•ˆí•˜ê²Œ 'ì•„~' ì†Œë¦¬ë¥¼ ë‚´ì£¼ì„¸ìš”. (${TOTAL_DURATION - elapsedTime}ì´ˆ)`}
              {currentPhase === 'complete' && 'ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‚˜ë§Œì˜ ì‚¬ìš´ë“œíŠ¸ë™ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.'}
            </p>
          </div>

          {/* Visualizer */}
          <div className="relative w-full aspect-square bg-black rounded-lg overflow-hidden mb-4">
            {/* Face Scan Phase */}
            {currentPhase === 'face' && (
              <>
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  className="w-full h-full object-cover"
                />
                <div className="face-guideline active"></div>
                {!isCameraReady && (
                  <div className="absolute inset-0 bg-black/50 flex items-center justify-center">
                    <span className="text-neon-cyan">ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘...</span>
                  </div>
                )}
              </>
            )}
            
            {/* Voice Scan Phase */}
            {currentPhase === 'voice' && (
              <div className="w-full h-full bg-gray-800 flex items-center justify-center">
                <div className="text-center">
                  <Mic className="w-16 h-16 text-neon-cyan mx-auto mb-2" />
                  <p className="text-neon-cyan">ìŒì„± ë…¹ìŒ ì¤‘...</p>
                  <p className="text-sm text-gray-400 mt-1">
                    {isMicrophoneReady ? 'ë§ˆì´í¬ ì¤€ë¹„ ì™„ë£Œ' : 'ë§ˆì´í¬ ì´ˆê¸°í™” ì¤‘...'}
                  </p>
                </div>
              </div>
            )}
            
            {/* Ready/Complete Phase */}
            {(currentPhase === 'ready' || currentPhase === 'complete') && (
              <div className="absolute inset-0 bg-gray-800 flex items-center justify-center">
                <span className="text-gray-500">
                  {currentPhase === 'ready' ? 'ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...' : 'ì¸¡ì • ì™„ë£Œ!'}
                </span>
              </div>
            )}
          </div>
          
          {/* Progress Bar */}
          <div className="w-full bg-gray-700/50 rounded-full h-4 mb-6">
            <div 
              className="bg-gradient-to-r from-neon-cyan to-neon-sky h-4 rounded-full transition-all duration-500"
              style={{ width: `${progress}%` }}
            ></div>
          </div>

          {/* Control Button */}
          <button 
            onClick={currentPhase === 'complete' ? goToResults : () => setShowConsentModal(true)}
            disabled={isMeasuring}
            className={`w-full font-bold py-4 px-6 rounded-lg transition-all duration-300 shadow-lg text-xl ${
              currentPhase === 'complete'
                ? 'bg-gradient-to-r from-green-500 to-emerald-600 hover:from-green-600 hover:to-emerald-700 text-white'
                : isMeasuring
                ? 'bg-gray-600 text-gray-400 cursor-not-allowed opacity-75'
                : 'bg-gradient-to-r from-neon-cyan to-neon-sky hover:from-neon-sky hover:to-neon-cyan text-gray-900 hover:shadow-neon-cyan/50'
            }`}
          >
            {currentPhase === 'ready' && '35ì´ˆ ì¸¡ì • ì‹œì‘í•˜ê¸°'}
            {isMeasuring && 'ì¸¡ì • ì¤‘...'}
            {currentPhase === 'complete' && 'ê²°ê³¼ ë³´ê¸°'}
          </button>

          {/* Reset Button (when measuring) */}
          {isMeasuring && (
            <button 
              onClick={resetMeasurement}
              className="w-full mt-3 bg-gray-600 hover:bg-gray-700 text-white font-medium py-2 px-4 rounded-lg transition-all duration-300"
            >
              ì¸¡ì • ì¤‘ë‹¨
            </button>
          )}
        </div>
      </div>

      {/* Error Display */}
      {error && (
        <div className="fixed top-4 left-4 right-4 bg-red-900/20 border border-red-500/50 rounded-lg p-4 animate-fade-in">
          <div className="flex items-center space-x-2 text-red-400">
            <span className="text-lg">âš ï¸</span>
            <span className="font-medium">{error}</span>
          </div>
          <button 
            onClick={() => setError(null)} 
            className="text-red-300 hover:text-red-100 text-sm mt-2"
          >
            ë‹«ê¸°
          </button>
        </div>
      )}

      {/* ê°œì¸ì •ë³´ë³´í˜¸ ë™ì˜ ëª¨ë‹¬ */}
      {showConsentModal && (
        <div className="fixed inset-0 bg-black/50 backdrop-blur-sm flex items-center justify-center z-50 animate-fade-in">
          <div className="glass-card p-8 max-w-2xl mx-4 max-h-[90vh] overflow-y-auto">
            <h3 className="text-2xl font-bold text-neon-cyan mb-6 text-center">
              ğŸ›¡ï¸ ê°œì¸ì •ë³´ë³´í˜¸ ë™ì˜
            </h3>
            
            <div className="space-y-4 mb-6">
              {/* í•„ìˆ˜ ë™ì˜ í•­ëª© */}
              <div className="flex items-start space-x-3">
                <input
                  type="checkbox"
                  id="modal-required-consent"
                  checked={privacyConsent.requiredConsent}
                  onChange={(e) => setPrivacyConsent(prev => ({ ...prev, requiredConsent: e.target.checked }))}
                  className="mt-1 w-5 h-5 bg-gray-800 border-gray-600 text-neon-cyan focus:ring-neon-cyan rounded"
                />
                <div className="flex-1">
                  <label htmlFor="modal-required-consent" className="font-medium text-white cursor-pointer">
                    í•„ìˆ˜ ë™ì˜ í•­ëª©
                  </label>
                  <p className="text-sm text-gray-400 mt-1">
                    ì–¼êµ´ ì˜ìƒ, ìŒì„± ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„, ì¸¡ì • ê²°ê³¼ ì €ì¥
                  </p>
                </div>
              </div>
              
              {/* ì„ íƒ ë™ì˜ í•­ëª© */}
              <div className="flex items-start space-x-3">
                <input
                  type="checkbox"
                  id="modal-optional-consent"
                  checked={privacyConsent.optionalConsent}
                  onChange={(e) => setPrivacyConsent(prev => ({ ...prev, optionalConsent: e.target.checked }))}
                  className="mt-1 w-5 h-5 bg-gray-800 border-gray-600 text-neon-cyan focus:ring-neon-cyan rounded"
                />
                <div className="flex-1">
                  <label htmlFor="modal-optional-consent" className="font-medium text-white cursor-pointer">
                    ì„ íƒ ë™ì˜ í•­ëª©
                  </label>
                  <p className="text-sm text-gray-400 mt-1">
                    ê°œì¸ ë§ì¶¤ ê±´ê°• ì¡°ì–¸, ì„œë¹„ìŠ¤ ê°œì„ ì„ ìœ„í•œ ë°ì´í„° í™œìš©
                  </p>
                </div>
              </div>
            </div>

            {/* ë™ì˜ í›„ ì¸¡ì • ì‹œì‘ ë²„íŠ¼ */}
            <div className="flex space-x-4 justify-center">
              <button
                onClick={() => setShowConsentModal(false)}
                className="btn-secondary px-6 py-3"
              >
                ì·¨ì†Œ
              </button>
              <button
                onClick={() => {
                  if (privacyConsent.requiredConsent) {
                    setShowConsentModal(false);
                    startMeasurement();
                  }
                }}
                disabled={!privacyConsent.requiredConsent}
                className={`px-6 py-3 rounded-lg font-bold transition-all duration-300 ${
                  privacyConsent.requiredConsent
                    ? 'bg-gradient-to-r from-neon-cyan to-neon-sky hover:from-neon-sky hover:to-neon-cyan text-gray-900 shadow-lg hover:shadow-neon-cyan/50'
                    : 'bg-gray-600 text-gray-400 cursor-not-allowed'
                }`}
              >
                {privacyConsent.requiredConsent ? 'ë™ì˜í•˜ê³  ì¸¡ì • ì‹œì‘' : 'í•„ìˆ˜ ë™ì˜ í›„ ì¸¡ì • ê°€ëŠ¥'}
              </button>
            </div>

            {/* ê°œì¸ì •ë³´ë³´í˜¸ ê´€ë ¨ ì•ˆë‚´ */}
            <p className="text-xs text-gray-500 text-center mt-4">
              ëª¨ë“  ë°ì´í„°ëŠ” ë¹„ì‹ë³„ ì²˜ë¦¬ë˜ì–´ ì•ˆì „í•˜ê²Œ ê´€ë¦¬ë©ë‹ˆë‹¤.
            </p>
          </div>
        </div>
      )}
    </div>
  );
}